\documentclass{beamer}
%Information to be included in the title page:
\title{Optimization notes}
\author{Ying Jia Lin}
\institute{National Cheng Kung University}

\date{May 3rd, 2021}
\begin{document}  
\frame{\titlepage}            
\begin{frame}
    \frametitle{Directional derivative}
    From a starting point $\underline{x}_0$ and a given dirction $\underline{u}$:
    \setbeamertemplate{itemize items}[circle]
    \begin{itemize}
        \item $\underline{x}(\lambda)=\underline{x}_0+\lambda \underline{u}$
        \begin{itemize}
            \item $\lambda$ is a scalar.
        \end{itemize}
        \item \alert{$d\underline{x}=\underline{u}d\lambda$}
        \begin{itemize}
            \item For a small change in $\lambda$.
        \end{itemize}
        \item $F(\lambda)=f(\underline{x}_0+\lambda\underline{u})$
        \begin{flalign*}
            &\begin{aligned}
            dF=df&=(\triangledown f(\underline{x}))^\top d\underline{x}\\
                 &=(\triangledown f(\underline{x}))^\top \alert{\underline{u}d \lambda}
                 =\triangledown ^\top f\underline{u}\lambda
            \end{aligned}&&
        \end{flalign*}
        \item $\frac{df}{d\lambda}=\triangledown ^\top f\underline{u}$
        \begin{itemize}
            \item If $f$ is minimized at $\underline{x}^*=\underline{x}_0+\lambda\underline{u}$, then:
            \begin{itemize}
                \item $\triangledown f(\underline{x}^*))^\top f\underline{u}=0$
                \item gradient $f$ evaluated at the minimum point is orthogonalto $\underline{u}$.
            \end{itemize}
        \end{itemize}
    \end{itemize}
\end{frame}
\begin{frame}
    \frametitle{Weierstrass Theorem}
    If $f(\underline{x})$ is continuous on a nonempty feasible set that is cloased and bounded,
    then $f(\underline{x})$ has a global minimum in this set.
    \begin{itemize}
        \item A set $S$ is bounded if for any point $\underline{x}$ in $S$, we have $\underline{x}^\top \underline{x}<c$
        \begin{itemize}
            \item $c$ is a finite positive number.
        \end{itemize}
    \end{itemize}
    
\end{frame}
\begin{frame}
    \frametitle{Single-variable unconstrained optimization}
    \setbeamertemplate{itemize items}[circle]
    \begin{itemize}
        \item Necessary condition
        \begin{itemize}
            \item If a function $f(x)$ has a local minimum at $x=x^*$,
            and $f'(x)$ exists as a finite number at $x=x^*$, then $f'(x^*)=0.$
        \end{itemize}
        \item Sufficient condition
        \begin{itemize}
            \item Suppose $f'(x^*)=f''(x^*)=\dots =f^{(m-1)}(x^*)=0$,
            but $f^{(m-1)}(x^*)\neq 0$, then $f(x^*)$ is:
            \begin{itemize}
                \item 1. a local minimum if $f^{(m-1)}(x^*)>0$ and $m$ is even.
                \item 2. a local maximum if $f^{(m-1)}(x^*)<0$ and $m$ is even.
                \item 3. neither a maximum nor a minimum if $m$ is odd.
            \end{itemize}
        \end{itemize}     
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Multi-variable unconstrained optimization (1)}
    Definition of $r^{th}$ differential of function $f$:
    \begin{flalign*}
        &\begin{aligned}
            d^rf(\underline{x}^*)=\sum^n_{i=1}\sum^n_{j=1}\dots\sum^n_{k=1}h_ih_j\dots h_k\frac{\partial^r{f(\underline{x}^*)}}{\partial{x_i}\partial{x_j}\dots\partial{x_k}}
        \end{aligned}&&
    \end{flalign*}
    \textbf{Example}
    
    When (order) $r=2$ and (number of variables) $n=3$, we have:

    \begin{flalign*}
        &\begin{aligned}
            d^2f(\underline{x}^*)&=d^2f(x_1^*, x_2^*, x_3^*)=\sum^3_{i=1}\sum^3_{j=1}h_ih_j\frac{\partial^2f(\underline{x}^*)}{\partial x_i\partial x_j}\\
            &=h^2_1\frac{\partial^2f(\underline{x}^*)}{\partial x^2_1}+
            h^2_2\frac{\partial^2f(\underline{x}^*)}{\partial x^2_2}+
            h^2_3\frac{\partial^2f(\underline{x}^*)}{\partial x^2_3} \\
            &+2h_1h_2\frac{\partial^2f(\underline{x}^*)}{\partial x_1\partial x_2}+
            2h_2h_3\frac{\partial^2f(\underline{x}^*)}{\partial x_2\partial x_3}+
            2h_1h_3\frac{\partial^2f(\underline{x}^*)}{\partial x_1\partial x_3}
        \end{aligned}&&
    \end{flalign*}
\end{frame}


\begin{frame}
    \frametitle{Multi-variable unconstrained optimization (2)}

\end{frame}

\end{document}